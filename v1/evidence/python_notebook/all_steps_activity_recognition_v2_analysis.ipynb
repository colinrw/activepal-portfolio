{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import math_helper\n",
    "from sensors.activpal import *\n",
    "from utils import read_functions\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import f1_score, plot_confusion_matrix, confusion_matrix, accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activpal = Activpal()\n",
    "\n",
    "features_columns = ['standard_deviation_x', 'mean_x', 'standard_deviation_y', 'mean_y','standard_deviation_z', 'mean_z', 'activiteit']\n",
    "activities = ['lopen', 'rennen', 'springen', 'staan', 'traplopen', 'zitten']\n",
    "activity_columns = ['activity_walking', 'activity_running', 'activity_jumping', 'activity_standing', 'activity_traplopen', 'activity_sitten']\n",
    "\n",
    "segment_size = 6.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_correspondent(correspondent):\n",
    "    features_df = pd.DataFrame(columns=features_columns, index=pd.to_datetime([]))\n",
    "\n",
    "    # Getting dataset for a correspodent\n",
    "    activities_df = read_functions.read_activities(correspondent)\n",
    "\n",
    "    for activity_name in activities:\n",
    "        activity = activities_df.loc[activity_name]\n",
    "        if not activity.empty:\n",
    "            start_time = activity.start\n",
    "            stop_time = activity.stop\n",
    "            activpal_df = activpal.read_data(correspondent, start_time, stop_time)\n",
    "\n",
    "            # denormalizing dataset\n",
    "            activpal_df['x'] = math_helper.convert_value_to_g(activpal_df['pal_accX'])\n",
    "            activpal_df['y'] = math_helper.convert_value_to_g(activpal_df['pal_accY'])\n",
    "            activpal_df['z'] = math_helper.convert_value_to_g(activpal_df['pal_accZ'])\n",
    "\n",
    "            date_range = pd.date_range(start_time, stop_time, freq=str(segment_size) + 'S')\n",
    "            for time in date_range:\n",
    "                segment_time = time + pd.DateOffset(seconds=segment_size)\n",
    "                activpal_segment = activpal_df[(activpal_df.index >= time) & (activpal_df.index <= segment_time)]\n",
    "\n",
    "                stdev_x =  statistics.stdev(activpal_segment['x']) if len(activpal_segment['x']) >= 2 else 0\n",
    "                mean_x = activpal_segment['x'].mean()\n",
    "\n",
    "                stdev_y =  statistics.stdev(activpal_segment['y']) if len(activpal_segment['y']) >= 2 else 0\n",
    "                mean_y = activpal_segment['y'].mean()\n",
    "\n",
    "                stdev_z =  statistics.stdev(activpal_segment['z']) if len(activpal_segment['z']) >= 2 else 0\n",
    "                mean_z = activpal_segment['z'].mean()  \n",
    "\n",
    "\n",
    "                features_df.loc[segment_time] = [stdev_x, mean_x, stdev_y, mean_y, stdev_z, mean_z, activity_name]\n",
    "\n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_all_correspondents():\n",
    "    all_features_df = pd.DataFrame(index=pd.to_datetime([]))\n",
    "\n",
    "    for directory in os.walk('../../data'):\n",
    "        if directory[0] == '../../data':\n",
    "            for respDirect in directory[1]:\n",
    "                if respDirect not in ['output', 'throughput', 'Test data','.ipynb_checkpoints', 'BMR035', 'BMR100', 'BMR051', 'BMR027']:\n",
    "                    print(\"Extracting \" + respDirect)\n",
    "                    features_df = extract_features_from_correspondent(respDirect)\n",
    "                    all_features_df = pd.concat([all_features_df, features_df])\n",
    "\n",
    "    print(\"Done extracting features\")\n",
    "\n",
    "    return all_features_df\n",
    "\n",
    "def extract_features_from_all_test_correspondents():\n",
    "    all_features_df = pd.DataFrame(index=pd.to_datetime([]))\n",
    "\n",
    "    for subject in test_subject:\n",
    "        print(\"Extracting \" + subject)\n",
    "        features_df = extract_features_from_correspondent(subject)\n",
    "        all_features_df = pd.concat([all_features_df, features_df])\n",
    "\n",
    "    print(\"Done extracting features from test users\")\n",
    "\n",
    "    return all_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dataset = extract_features_from_all_correspondents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dataset['activiteit'].value_counts().plot.bar(ylabel='rows count',xlabel='activties', title='unbalanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset_by_activity(dataset):\n",
    "    highest_frequency  = dataset.groupby('activiteit').count()['standard_deviation_x'].max()\n",
    "    unbalanced_dataset = dataset.copy()\n",
    "    \n",
    "    for activity_name in unbalanced_dataset.activiteit.unique():\n",
    "        activity_data = unbalanced_dataset[unbalanced_dataset['activiteit'] == activity_name]\n",
    "        \n",
    "        multiplier =  int(highest_frequency / len(activity_data)) - 1\n",
    "        unbalanced_dataset = unbalanced_dataset.append([activity_data] * multiplier, ignore_index=True)    \n",
    "        \n",
    "        activity_amount = len(unbalanced_dataset[ unbalanced_dataset['activiteit'] == activity_name])\n",
    "        missing_amount = highest_frequency - activity_amount\n",
    "        unbalanced_dataset = unbalanced_dataset.append(activity_data[:missing_amount], ignore_index=True)    \n",
    "\n",
    "    return unbalanced_dataset\n",
    "\n",
    "#features_dataset = balance_dataset_by_activity(features_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dataset['activiteit'].value_counts().plot.bar(ylabel='rows count',xlabel='activties',title='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dataset[activity_columns] = 0\n",
    "\n",
    "features_dataset.loc[(features_dataset['activiteit'] == 'lopen'), 'activity_walking'] = 1\n",
    "features_dataset.loc[(features_dataset['activiteit'] == 'rennen'), 'activity_running'] = 1\n",
    "features_dataset.loc[(features_dataset['activiteit'] == 'springen'), 'activity_jumping'] = 1\n",
    "features_dataset.loc[(features_dataset['activiteit'] == 'staan'), 'activity_standing'] = 1\n",
    "features_dataset.loc[(features_dataset['activiteit'] == 'traplopen'), 'activity_traplopen'] = 1\n",
    "features_dataset.loc[(features_dataset['activiteit'] == 'zitten'), 'activity_sitten'] = 1\n",
    "features_dataset.drop('activiteit', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill_na_columns = ['standard_deviation_x', 'mean_x', 'standard_deviation_y', 'mean_y','standard_deviation_z', \n",
    "#                    'mean_z']\n",
    "\n",
    "#for column in fill_na_columns:\n",
    "#    features_dataset[column].fillna(0, inplace=True)\n",
    "features_dataset.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing feature dataset for learning\n",
    "### Splitting in x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = features_dataset[features_columns[:-1]]\n",
    "y = features_dataset[['activity_walking', 'activity_running', 'activity_jumping', 'activity_standing', 'activity_traplopen', 'activity_sitten']]\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(x,y, test_size=0.2, random_state=23, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random tree forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "rfc.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_y = rfc.predict(valid_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(valid_y, prediction_y, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(valid_y,prediction_y, target_names=['activity_walking', 'activity_running', 'activity_jumping', 'activity_standing', 'activity_traplopen',\n",
    "                  'activity_sitten'], zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "\n",
    "#confusion_matrix(valid_y, prediction_y)\n",
    "cm = confusion_matrix(valid_y.values.argmax(axis=1), prediction_y.argmax(axis=1), normalize='true')\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index=activities, columns=activities)\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True, cmap='Blues')\n",
    "\n",
    "plt.title(\"Validation dataset\")\n",
    "plt.xlabel(\"predicted label\")\n",
    "plt.ylabel(\"true label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Summary\n",
    "\n",
    "Random seed: 23\n",
    "n_estimators: 20\n",
    "\n",
    "\n",
    "|Features| |\n",
    "|-----| ----|\n",
    "| standard_deviation_x| mean_x|\n",
    "| standard_deviation_y| mean_y|\n",
    "| standard_deviation_z| mean_z|\n",
    "\n",
    "| Time range | Accuracy | Precision |  Recall |F1|\n",
    "| ------ | ------ | ------ | ------ |------- |\n",
    "| 0.4S  | 93% | 96% | 93% | 95% | \n",
    "| 0.8S  | 95% | 97% | 95% | 96% |\n",
    "| 1.0S  | 95% | 98% | 95% | 96% |\n",
    "| 1.6S  | 95% | 97% | 95% | 96% |\n",
    "| 2.0S  | 95% | 97% | 95% | 96% |\n",
    "| 3.2S  | 96% | 98% | 96% | 97% |\n",
    "| 4.0S  | 95% | 98% | 95% | 96% |\n",
    "| 6.4S  | 97% | 98% | 97% | 97% | \n",
    "| 8.0S  | 96% | 98% | 96% | 97% |\n",
    "| 10.0S | 96% | 99% | 96% | 97% |\n",
    "| 12.8S | 97% | 98% | 97% | 97% |\n",
    "\n",
    "Best results:\n",
    "\n",
    "| Time range | Accuracy | Precision |  Recall |F1|\n",
    "| ------ | ------ | ------ | ------ |------- |\n",
    "| 6.4S  | 97% | 98% | 97% | 97% | \n",
    "| 12.8S | 97% | 98% | 97% | 97% |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostics\n",
    "### Cross validation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "import seaborn as sn\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "pred_y = cross_val_predict(rfc, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = cross_val_score(rfc, x, y , scoring='accuracy')\n",
    "recall_scores = cross_val_score(rfc, x, y , scoring='recall_micro')\n",
    "precision_scores = cross_val_score(rfc, x, y , scoring='precision_micro')\n",
    "\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (accuracy_scores.mean(), accuracy_scores.std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (recall_scores.mean(), recall_scores.std() * 2))\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (precision_scores.mean(), precision_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "cm = confusion_matrix(y.values.argmax(axis=1), pred_y.argmax(axis=1), normalize='true')\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index=activities, columns=activities)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True, cmap='Blues')\n",
    "plt.title(\"Validation dataset\")\n",
    "plt.xlabel(\"predicted label\")\n",
    "plt.ylabel(\"true label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "accuracy_scores = np.array([])\n",
    "recall_scores = np.array([])\n",
    "precision_scores = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in skf.split(x, y):\n",
    "    x_train, y_train = x.iloc[train_index], y.iloc[train_index]\n",
    "    x_test, y_test = x.iloc[test_index], y.iloc[test_index]\n",
    "    \n",
    "    rfc = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "    rfc.fit(x_train, y_train)\n",
    "    \n",
    "    y_prediction = rfc.predict(x_test)\n",
    "    \n",
    "    accuracy_scores  = np.append(accuracy_scores, accuracy_score(y_test, y_prediction, normalize=True))\n",
    "    recall_scores    = np.append(recall_scores, recall_score(y_test, y_prediction, average='micro'))\n",
    "    precision_scores = np.append(precision_scores, precision_score(y_test, y_prediction, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyper parameter optimalization\n",
    "## n_estimator optimalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "n_estimator_numbers = range(1,200)\n",
    "\n",
    "for i in n_estimator_numbers:\n",
    "    rfc = RandomForestClassifier(n_estimators=i, random_state=0)\n",
    "    rfc.fit(train_x, train_y)\n",
    "    \n",
    "    predictions = rfc.predict(valid_x)\n",
    "    \n",
    "    accuracy_scores.append(accuracy_score(valid_y, predictions, normalize=True))\n",
    "    recall_scores.append(recall_score(valid_y, predictions, average='micro' ))\n",
    "    precision_scores.append(precision_score(valid_y, predictions, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_estimator_numbers, accuracy_scores, label='accuracy')\n",
    "plt.plot(n_estimator_numbers, recall_scores, label='recall')\n",
    "plt.plot(n_estimator_numbers, precision_scores, label='precision')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_features = extract_features_from_all_test_correspondents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = ['lopen', 'rennen', 'springen', 'staan', 'traplopen', 'zitten']\n",
    "\n",
    "test_set_features[['activity_walking_running', 'activity_jumping', 'activity_standing', 'activity_traplopen',\n",
    "                  'activity_sitten']] = 0\n",
    "\n",
    "test_set_features.loc[(test_set_features['activiteit'] == 'lopen'), 'activity_walking_running'] = 1\n",
    "test_set_features.loc[(test_set_features['activiteit'] == 'rennen'), 'activity_walking_running'] = 1\n",
    "test_set_features.loc[(test_set_features['activiteit'] == 'springen'), 'activity_jumping'] = 1\n",
    "test_set_features.loc[(test_set_features['activiteit'] == 'staan'), 'activity_standing'] = 1\n",
    "test_set_features.loc[(test_set_features['activiteit'] == 'traplopen'), 'activity_traplopen'] = 1\n",
    "test_set_features.loc[(test_set_features['activiteit'] == 'zitten'), 'activity_sitten'] = 1\n",
    "\n",
    "test_set_features.drop('activiteit', axis=1, inplace=True)\n",
    "test_set_features.dropna(how='any', inplace=True)\n",
    "\n",
    "test_set_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_set_features[['standard_deviation_x', 'mean_x', 'standard_deviation_y', 'mean_y','standard_deviation_z', 'mean_z']]\n",
    "test_y = test_set_features[['activity_walking_running', 'activity_jumping', 'activity_standing', 'activity_traplopen', 'activity_sitten']]\n",
    "\n",
    "prediction_y = rfc.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_y, prediction_y, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_y,prediction_y, target_names=['activity_walking_running' 'activity_jumping', 'activity_standing', 'activity_traplopen',\n",
    "                  'activity_sitten'], zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
